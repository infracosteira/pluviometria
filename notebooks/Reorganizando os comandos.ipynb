{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8bcfcdc-a349-487b-9edf-f830bfde23fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lendo dados das estações pluviometricas...\n"
     ]
    }
   ],
   "source": [
    "import zipfile as zipfile\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "print(\"\\nLendo dados das estações pluviometricas...\")\n",
    "\n",
    "for_concat = []\n",
    "with zipfile.ZipFile('../data/postos.zip', 'r') as t:\n",
    "    for arq in t.namelist():\n",
    "        if arq.endswith('.txt'):\n",
    "            with t.open(arq) as f:\n",
    "                df = pd.read_csv(f, delimiter=';')\n",
    "                # Extrair o ID do nome do arquivo e adicionar como uma nova coluna\n",
    "                df['id'] = arq.split('.')[0]\n",
    "                for_concat.append(df)\n",
    "\n",
    "# Exclude empty or all-NA entries before concatenation\n",
    "for_concat = [\n",
    "    df for df in for_concat if not df.empty and not df.isna().all().all()\n",
    "]\n",
    "\n",
    "registros_chuvas = pd.concat(for_concat)\n",
    "registros_chuvas.fillna(0, inplace=True)\n",
    "registros_chuvas.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reordenar as colunas para que 'id' seja a primeira\n",
    "cols = ['id'] + [col for col in registros_chuvas.columns if col != 'id']\n",
    "registros_chuvas = registros_chuvas[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1d8892f-9aed-45f8-a807-fc5116dbc06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtrando anos completos...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltrando anos completos...\")\n",
    "\n",
    "#pegar apenas os anos completos\n",
    "registros_chuvas['Anos'] = registros_chuvas['Anos'].astype(int)\n",
    "registros_chuvas['Meses'] = registros_chuvas['Meses'].astype(int)\n",
    "ano = dt.datetime.now().year\n",
    "Anos_completos = registros_chuvas\n",
    "Anos_completos = Anos_completos.loc[Anos_completos['Anos'] < ano]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fbfa536-53b4-4d1e-8424-55aca3716ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando o primeiro e o ultimo ano de registro de cada posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando o primeiro e o ultimo ano de registro de cada posto...\")\n",
    "\n",
    "# Verificar qual o primeiro ano de registro e o ultimo ano de registro de cada posto\n",
    "primeiro_e_ultimo_ano = Anos_completos.groupby('id')['Anos'].agg(['min', 'max'])\n",
    "primeiro_e_ultimo_ano.columns = ['Ano_inicial', 'Ano_final']\n",
    "Anos_completos = Anos_completos.merge(primeiro_e_ultimo_ano, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfe1aeee-ae6e-4150-8abb-52eaffc709ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar qual foi o primeiro mês registrado para cada posto no ano inicial\n",
    "ano_inicial_df = Anos_completos[Anos_completos['Anos'] == Anos_completos['Ano_inicial']]\n",
    "primeiro_mes_ano_inicial = ano_inicial_df.groupby('id')['Meses'].min().reset_index()\n",
    "primeiro_mes_ano_inicial.rename(columns={'Meses': 'Primeiro_mes'}, inplace=True)\n",
    "Anos_completos = Anos_completos.merge(primeiro_mes_ano_inicial, on='id', how='left')\n",
    "\n",
    "# Encontrar qual foi o último mês registrado para cada posto no ano final\n",
    "ano_final_df = Anos_completos[Anos_completos['Anos'] == Anos_completos['Ano_final']]\n",
    "ultimo_mes_ano_final = ano_final_df.groupby('id')['Meses'].max().reset_index()\n",
    "ultimo_mes_ano_final.rename(columns={'Meses': 'Ultimo_mes'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f15b32e2-2c55-4acb-95d4-22a4372b9083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def preencher_anos_faltantes(df):\n",
    "    postos_unicos = df[['id', 'Postos', 'Municipios']].drop_duplicates()\n",
    "    anos_faltantes = []\n",
    "    ano_atual = datetime.now().year  # Obtém o ano atual\n",
    "\n",
    "    for _, row in postos_unicos.iterrows():\n",
    "        posto_id = row['id']\n",
    "        posto = row['Postos']\n",
    "        municipio = row['Municipios']\n",
    "\n",
    "        # Seleciona apenas os registros do posto específico\n",
    "        df_posto = df[(df['id'] == posto_id) & (df['Postos'] == posto) & (df['Municipios'] == municipio)]\n",
    "        \n",
    "        # Identifica o primeiro ano registrado, preenchendo se for NaN\n",
    "        if df_posto['Anos'].notna().any():\n",
    "            ano_inicial = int(df_posto['Anos'].min())\n",
    "        else:\n",
    "            print(f\"Aviso: Nenhum ano encontrado para o posto ID {posto_id} - {posto}, município {municipio}. Preenchendo com 999.\")\n",
    "            ano_inicial = ano_atual  # Usar o ano atual como referência mínima\n",
    "        \n",
    "        # Determina o intervalo de anos\n",
    "        anos_completos = set(range(ano_inicial, ano_atual))\n",
    "        anos_registrados = set(df_posto['Anos'].dropna().unique())\n",
    "        \n",
    "        # Determina os anos que estão faltando\n",
    "        anos_faltantes_posto = anos_completos - anos_registrados\n",
    "\n",
    "        # Preenche os anos faltantes com os meses e dias como 999.0\n",
    "        for ano in anos_faltantes_posto:\n",
    "            for mes in range(1, 13):\n",
    "                falha = {\n",
    "                    'id': posto_id,\n",
    "                    'Municipios': municipio,\n",
    "                    'Postos': posto,\n",
    "                    'Latitude': df_posto['Latitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Longitude': df_posto['Longitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Anos': ano,\n",
    "                    'Meses': mes,\n",
    "                    'Total': 999.0,\n",
    "                    **{f'Dia{i}': 999.0 for i in range(1, 32)}\n",
    "                }\n",
    "                anos_faltantes.append(falha)\n",
    "\n",
    "    # Cria um DataFrame com os anos faltantes e concatena ao original\n",
    "    df_faltantes = pd.DataFrame(anos_faltantes)\n",
    "    df = pd.concat([df, df_faltantes], ignore_index=True)\n",
    "    df.sort_values(by=['id', 'Postos', 'Municipios', 'Anos', 'Meses'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preencher_meses_faltantes(df):\n",
    "    postos_unicos = df[['id', 'Postos', 'Municipios']].drop_duplicates()\n",
    "    meses_faltantes = []\n",
    "\n",
    "    for _, row in postos_unicos.iterrows():\n",
    "        posto_id = row['id']\n",
    "        posto = row['Postos']\n",
    "        municipio = row['Municipios']\n",
    "\n",
    "        # Seleciona apenas os registros do posto específico\n",
    "        df_posto = df[(df['id'] == posto_id) & (df['Postos'] == posto) & (df['Municipios'] == municipio)]\n",
    "        \n",
    "        anos_registrados = df_posto['Anos'].dropna().unique()\n",
    "\n",
    "        for ano in anos_registrados:\n",
    "            df_ano = df_posto[df_posto['Anos'] == ano]\n",
    "            meses_registrados = set(df_ano['Meses'].dropna().unique())\n",
    "            meses_completos = set(range(1, 13))\n",
    "            \n",
    "            # Determina os meses que estão faltando no ano\n",
    "            meses_faltantes_ano = meses_completos - meses_registrados\n",
    "\n",
    "            for mes in meses_faltantes_ano:\n",
    "                falha = {\n",
    "                    'id': posto_id,\n",
    "                    'Municipios': municipio,\n",
    "                    'Postos': posto,\n",
    "                    'Latitude': df_posto['Latitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Longitude': df_posto['Longitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Anos': ano,\n",
    "                    'Meses': mes,\n",
    "                    'Total': 999.0,\n",
    "                    **{f'Dia{i}': 999.0 for i in range(1, 32)}\n",
    "                }\n",
    "                meses_faltantes.append(falha)\n",
    "\n",
    "    # Cria um DataFrame com os meses faltantes e concatena ao original\n",
    "    df_faltantes = pd.DataFrame(meses_faltantes)\n",
    "    df = pd.concat([df, df_faltantes], ignore_index=True)\n",
    "    df.sort_values(by=['id', 'Postos', 'Municipios', 'Anos', 'Meses'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Preencher anos e meses faltantes\n",
    "Anos_completos = preencher_anos_faltantes(Anos_completos)\n",
    "Anos_completos = preencher_meses_faltantes(Anos_completos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4295ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivos CSV gerados para cada posto na pasta 'postos_solo'.\n"
     ]
    }
   ],
   "source": [
    "# Converter colunas numéricas de string para float\n",
    "numeric_cols = ['Total'] + [f'Dia{i}' for i in range(1, 32)]\n",
    "for col in numeric_cols:\n",
    "    Anos_completos[col] = Anos_completos[col].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "output_dir = \"../data/postos_solo\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "for posto_id in Anos_completos['id'].unique():\n",
    "    registros_posto = Anos_completos[Anos_completos['id'] == posto_id]\n",
    "    nome_posto = registros_posto['Postos'].iloc[0].replace(' ', '_')\n",
    "    nome_posto = remover_acentos(nome_posto)  # Remover acentos\n",
    "    nome_arquivo = os.path.join(output_dir, f\"{posto_id}_{nome_posto}.csv\")\n",
    "    registros_posto.to_csv(nome_arquivo, index=False, decimal=',')\n",
    "\n",
    "print(\"\\nArquivos CSV gerados para cada posto na pasta 'postos_solo'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01bcc81d-bb22-4da7-8a19-5378f533d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Repreenchendo os novos registros com os meses e anos de primeiro registro\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRepreenchendo os novos registros com os meses e anos de primeiro registro\")\n",
    "\n",
    "primeiro_e_ultimo_ano = Anos_completos.groupby('id')['Anos'].agg(['min', 'max'])\n",
    "primeiro_e_ultimo_ano.columns = ['Ano_inicial', 'Ano_final']\n",
    "Anos_completos = Anos_completos.merge(primeiro_e_ultimo_ano, on='id')\n",
    "\n",
    "# Check if the columns exist before attempting to drop them\n",
    "if 'Ano_inicial_x' in Anos_completos.columns and 'Ano_final_x' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Ano_inicial_x', 'Ano_final_x'], inplace=True)\n",
    "\n",
    "Anos_completos = Anos_completos.merge(primeiro_mes_ano_inicial, on='id', how='left')\n",
    "Anos_completos = Anos_completos.merge(ultimo_mes_ano_final, on='id', how='left')\n",
    "\n",
    "# Check if the column exists before attempting to drop it\n",
    "if 'Primeiro_mes_x' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Primeiro_mes_x'], inplace=True)\n",
    "\n",
    "Anos_completos.rename(columns={\n",
    "    'Ano_inicial_y': 'Ano_inicial',\n",
    "    'Ano_final_y': 'Ano_final',\n",
    "    'Primeiro_mes_y': 'Primeiro_mes'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff779014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando quantos meses de falha existem parada cada posto\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando quantos meses de falha existem parada cada posto\")\n",
    "\n",
    "df_sem_extras = Anos_completos.drop(\n",
    "    columns=['Primeiro_mes', 'Ultimo_mes', 'Ano_inicial', 'Ano_final'])\n",
    "\n",
    "# Substituir os valores 888.0 por NaN e depois remover essas colunas\n",
    "df_sem_extras.replace(888.0, pd.NA, inplace=True)\n",
    "df_sem_extras.dropna(axis=1, how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8708f895-4d28-4256-9c66-4b142dd22e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando quantos meses de falha existem para cada posto\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando quantos meses de falha existem para cada posto\")\n",
    "dias_cols = [f'Dia{i}' for i in range(1, 32)]\n",
    "\n",
    "def verificar_meses_falha(df):\n",
    "    df['Mes_falha'] = df[dias_cols].apply(lambda row: any(day == 999.0 for day in row), axis=1)\n",
    "    meses_falha_por_posto = df.groupby('id')['Mes_falha'].sum()\n",
    "    return meses_falha_por_posto\n",
    "\n",
    "meses_falha_por_posto = verificar_meses_falha(Anos_completos)\n",
    "Anos_completos = Anos_completos.merge(meses_falha_por_posto.rename('Meses_de_Falha'), on='id', how='left')\n",
    "Anos_completos = Anos_completos.drop(columns=['Mes_falha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4788df56-ca3b-4395-abb1-d5d070337a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando intervalo de dias, meses e anos totais de falhas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\\nCalculando intervalo de dias, meses e anos totais de falhas por posto...\"\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def calcular_intervalo_dias(row):\n",
    "    ano_inicial = int(row['Ano_inicial'])\n",
    "    ano_final = int(row['Ano_final'])\n",
    "    data_inicial = datetime(ano_inicial, 1, 1)\n",
    "    data_final = datetime(ano_final, 12, 31)\n",
    "\n",
    "    intervalo = (data_final - data_inicial).days + 1\n",
    "    \n",
    "    for year in range(ano_inicial, ano_final + 1):\n",
    "        if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "            if year == ano_inicial and data_inicial.month > 2:\n",
    "                continue\n",
    "            if year == ano_final and data_final.month < 2:\n",
    "                continue\n",
    "            intervalo += 1\n",
    "\n",
    "    return intervalo\n",
    "\n",
    "def contar_dias_falha(row):\n",
    "    return sum(row[dia] == 999.0 for dia in dias_cols)\n",
    "\n",
    "Anos_completos['Ano_inicial'] = Anos_completos['Ano_inicial'].astype(int)\n",
    "Anos_completos['Ano_final'] = Anos_completos['Ano_final'].astype(int)\n",
    "\n",
    "Anos_completos['Intervalo_dias'] = Anos_completos.apply(calcular_intervalo_dias, axis=1)\n",
    "Anos_completos['Dias_de_Falha'] = Anos_completos.apply(contar_dias_falha, axis=1)\n",
    "\n",
    "total_falhas_por_posto = Anos_completos.groupby('id')['Dias_de_Falha'].sum().reset_index()\n",
    "total_falhas_por_posto.rename(columns={'Dias_de_Falha': 'Total_Falhas'}, inplace=True)\n",
    "\n",
    "Anos_completos = Anos_completos.merge(total_falhas_por_posto, on='id', how='left')\n",
    "Anos_completos['Intervalo_anos'] = (Anos_completos['Ano_final'].astype(int) - Anos_completos['Ano_inicial'].astype(int)) + 1\n",
    "Anos_completos['Intervalo_meses'] = Anos_completos['Intervalo_anos'] * 12\n",
    "\n",
    "Anos_completos.drop(columns=['Dias_de_Falha'], inplace=True)\n",
    "Anos_completos['dias_medidos'] = Anos_completos['Intervalo_dias'] - Anos_completos['Total_Falhas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c7adeea-d814-4ba8-bb46-df3473c364c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a porcentagem de dias de falhas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a porcentagem de dias de falhas por posto...\")\n",
    "\n",
    "Anos_completos['Porcentagem_dias_Falhas'] = (\n",
    "    Anos_completos['Total_Falhas'] / Anos_completos['Intervalo_dias']) * 100\n",
    "Anos_completos['Porcentagem_dias_Falhas'] = Anos_completos[\n",
    "    'Porcentagem_dias_Falhas'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a854f833-4ddf-42f1-80bb-10e533202f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando anos de falha por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando anos de falha por posto...\")\n",
    "\n",
    "# Verificar quantos anos com falha tiveram no intervalo por posto\n",
    "def contar_anos_falha(df):\n",
    "    df['Ano_com_falha'] = df[dias_cols].apply(lambda row: any(day == 999.0 for day in row), axis=1)\n",
    "    anos_falha = df.groupby(['id', 'Anos'])['Ano_com_falha'].any().reset_index()\n",
    "    anos_falha_por_posto = anos_falha.groupby('id')['Ano_com_falha'].sum().reset_index()\n",
    "    anos_falha_por_posto.rename(columns={'Ano_com_falha': 'Anos_de_Falha'}, inplace=True)\n",
    "    return anos_falha_por_posto\n",
    "\n",
    "anos_falha_por_posto = contar_anos_falha(Anos_completos)\n",
    "Anos_completos = Anos_completos.merge(anos_falha_por_posto, on='id', how='left')\n",
    "Anos_completos.drop(columns=['Ano_com_falha'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec99a7f2-4669-45eb-993f-44f5ca1c6504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando anos completos medidos por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando anos completos medidos por posto...\")\n",
    "\n",
    "# Agrupar por id para garantir que os dados são do mesmo posto\n",
    "Anos_completos['Anos_completos_medidos'] = Anos_completos.groupby('id')['Intervalo_anos'].transform('first') - Anos_completos.groupby('id')['Anos_de_Falha'].transform('first')\n",
    "\n",
    "Anos_completos['Porcentagem_anos_Falhas'] = (\n",
    "    Anos_completos['Anos_de_Falha'] / Anos_completos['Intervalo_anos']) * 100\n",
    "Anos_completos['Porcentagem_anos_Falhas'] = Anos_completos[\n",
    "    'Porcentagem_anos_Falhas'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e40111eb-d6a6-45b9-8a26-3b88c5d1a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a média mensal de chuvas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a média mensal de chuvas por posto...\")\n",
    "\n",
    "def dados_validos(df):\n",
    "    # Verificar se todos os dias do mês não são 999.0\n",
    "    df['Mes_valido'] = df[dias_cols].apply(lambda row: all(day != 999.0 for day in row), axis=1)\n",
    "    \n",
    "    # Filtrar apenas os meses válidos\n",
    "    df_validos = df[df['Mes_valido']].copy()\n",
    "    \n",
    "    # Remover a coluna auxiliar 'Mes_valido'\n",
    "    df_validos.drop(columns=['Mes_valido'], inplace=True)\n",
    "    \n",
    "    return df_validos\n",
    "\n",
    "df_dados_validos = dados_validos(Anos_completos)\n",
    "\n",
    "# Calcular a média mensal de chuvas por posto\n",
    "ids_unicos = df_dados_validos['id'].unique()\n",
    "\n",
    "medias_mensais = []\n",
    "\n",
    "for posto_id in ids_unicos:\n",
    "    df_posto = df_dados_validos[df_dados_validos['id'] == posto_id]\n",
    "    \n",
    "    # Inicializar variáveis para somar os totais e contadores para cada mês\n",
    "    jan_total = fev_total = mar_total = apr_total = may_total = jun_total = 0\n",
    "    jul_total = aug_total = sep_total = oct_total = nov_total = dec_total = 0\n",
    "    \n",
    "    jan_count = fev_count = mar_count = apr_count = may_count = jun_count = 0\n",
    "    jul_count = aug_count = sep_count = oct_count = nov_count = dec_count = 0\n",
    "    \n",
    "    for _, row in df_posto.iterrows():\n",
    "        if row['Meses'] == 1:\n",
    "            jan_total += row['Total']\n",
    "            jan_count += 1\n",
    "        elif row['Meses'] == 2:\n",
    "            fev_total += row['Total']\n",
    "            fev_count += 1\n",
    "        elif row['Meses'] == 3:\n",
    "            mar_total += row['Total']\n",
    "            mar_count += 1\n",
    "        elif row['Meses'] == 4:\n",
    "            apr_total += row['Total']\n",
    "            apr_count += 1\n",
    "        elif row['Meses'] == 5:\n",
    "            may_total += row['Total']\n",
    "            may_count += 1\n",
    "        elif row['Meses'] == 6:\n",
    "            jun_total += row['Total']\n",
    "            jun_count += 1\n",
    "        elif row['Meses'] == 7:\n",
    "            jul_total += row['Total']\n",
    "            jul_count += 1\n",
    "        elif row['Meses'] == 8:\n",
    "            aug_total += row['Total']\n",
    "            aug_count += 1\n",
    "        elif row['Meses'] == 9:\n",
    "            sep_total += row['Total']\n",
    "            sep_count += 1\n",
    "        elif row['Meses'] == 10:\n",
    "            oct_total += row['Total']\n",
    "            oct_count += 1\n",
    "        elif row['Meses'] == 11:\n",
    "            nov_total += row['Total']\n",
    "            nov_count += 1\n",
    "        elif row['Meses'] == 12:\n",
    "            dec_total += row['Total']\n",
    "            dec_count += 1\n",
    "    \n",
    "    medias_mensais.append({\n",
    "        'id': posto_id,\n",
    "        'Media_Jan': jan_total / jan_count if jan_count else 999,\n",
    "        'Media_Fev': fev_total / fev_count if fev_count else 999,\n",
    "        'Media_Mar': mar_total / mar_count if mar_count else 999,\n",
    "        'Media_Apr': apr_total / apr_count if apr_count else 999,\n",
    "        'Media_May': may_total / may_count if may_count else 999,\n",
    "        'Media_Jun': jun_total / jun_count if jun_count else 999,\n",
    "        'Media_Jul': jul_total / jul_count if jul_count else 999,\n",
    "        'Media_Aug': aug_total / aug_count if aug_count else 999,\n",
    "        'Media_Sep': sep_total / sep_count if sep_count else 999,\n",
    "        'Media_Oct': oct_total / oct_count if oct_count else 999,\n",
    "        'Media_Nov': nov_total / nov_count if nov_count else 999,\n",
    "        'Media_Dec': dec_total / dec_count if dec_count else 999\n",
    "    })\n",
    "\n",
    "df_medias_mensais = pd.DataFrame(medias_mensais)\n",
    "Anos_completos = Anos_completos.merge(df_medias_mensais, on='id', how='left')\n",
    "# Preencher médias vazias com 999\n",
    "\n",
    "medias_cols = ['Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec']\n",
    "Anos_completos[medias_cols] = Anos_completos[medias_cols].fillna(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb20ace9-05b0-4ce6-b53c-e460548588ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a média anual de chuvas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a média anual de chuvas por posto...\")\n",
    "\n",
    "postos_unicos = Anos_completos['id'].unique()\n",
    "\n",
    "Anos_completos['Media_Anual'] = 0.0\n",
    "\n",
    "for posto_id in postos_unicos:\n",
    "    df_posto = Anos_completos[Anos_completos['id'] == posto_id]\n",
    "    intervalo_anos = df_posto['Intervalo_anos'].iloc[0]\n",
    "\n",
    "    # Check if all monthly averages are 999\n",
    "    if (df_posto[['Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec']] == 999).all(axis=None):\n",
    "        media_anual = 999\n",
    "    else:\n",
    "        soma_total_chuvas = df_posto[df_posto['Total'] != 999].groupby('Anos')['Total'].sum().sum()\n",
    "        media_anual = soma_total_chuvas / intervalo_anos\n",
    "\n",
    "    Anos_completos.loc[Anos_completos['id'] == posto_id, 'Media_Anual'] = media_anual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91b88347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anos_completos['Total_meses_intervalo'] = Anos_completos['Intervalo_anos'] * 12\n",
    "\n",
    "if 'Intervalo_meses' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Intervalo_meses'], inplace=True)\n",
    "\n",
    "Anos_completos['Numero_meses_completos'] = Anos_completos['Total_meses_intervalo'] - Anos_completos['Meses_de_Falha']\n",
    "\n",
    "def calcular_percentual_meses_falha(df):\n",
    "    df['Percentual_meses_falha'] = (df['Meses_de_Falha'] / df['Total_meses_intervalo']) * 100\n",
    "    df['Percentual_meses_falha'] = df['Percentual_meses_falha'].round(2)\n",
    "    return df\n",
    "\n",
    "Anos_completos = calcular_percentual_meses_falha(Anos_completos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62b8ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_resumo1 = [\n",
    "    'id','link_csv', 'Postos', 'Municipios', 'Latitude', 'Longitude', 'Ano_inicial', 'Ano_final',\n",
    "    'Primeiro_mes', 'Ultimo_mes', 'Intervalo_dias', 'dias_medidos', 'Total_Falhas',\n",
    "    'Porcentagem_dias_Falhas', 'Total_meses_intervalo', 'Numero_meses_completos',\n",
    "    'Meses_de_Falha', 'Percentual_meses_falha', 'Intervalo_anos', 'Anos_completos_medidos',\n",
    "    'Anos_de_Falha', 'Porcentagem_anos_Falhas', 'Media_Anual', 'Media_Jan', 'Media_Fev',\n",
    "    'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug',\n",
    "    'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec'\n",
    "    , 'Dia1', 'Dia2', 'Dia3', 'Dia4', 'Dia5', 'Dia6', 'Dia7', 'Dia8', 'Dia9', 'Dia10', 'Dia11', 'Dia12', 'Dia13', 'Dia14', 'Dia15', 'Dia16', 'Dia17', 'Dia18', 'Dia19', 'Dia20', 'Dia21', 'Dia22', 'Dia23', 'Dia24', 'Dia25', 'Dia26', 'Dia27', 'Dia28', 'Dia29', 'Dia30', 'Dia31'\n",
    "]\n",
    "\n",
    "database = Anos_completos.copy()\n",
    "\n",
    "database.drop(columns=['Mes_valido'], inplace=True)\n",
    "\n",
    "database.rename(columns={\n",
    "    'id': 'ID',\n",
    "    'Postos': 'Nome_Posto',\n",
    "    'Municipios': 'Nome_Municipio',\n",
    "    'Latitude': 'Coordenada_Y',\n",
    "    'Longitude': 'Coordenada_X',\n",
    "    'Ano_inicial': 'Ano_Inicio',\n",
    "    'Ano_final': 'Ano_Fim',\n",
    "    'Primeiro_mes': 'Mes_Inicio',\n",
    "    'Ultimo_mes': 'Mes_Fim',\n",
    "    'Intervalo_dias': 'Total_dias_intervalo',\n",
    "    'dias_medidos': 'Dias_dados_medidos',\n",
    "    'Total_Falhas': 'Dias_falhos',\n",
    "    'Porcentagem_dias_Falhas': 'Percentual_dias_falhos',\n",
    "    'Total_meses_intervalo': 'Total_meses_intervalo',\n",
    "    'Numero_meses_completos': 'Numero_meses_completos',\n",
    "    'Meses_de_Falha': 'Numero_meses_falha',\n",
    "    'Percentual_meses_falha': 'Percentual_meses_falha',\n",
    "    'Intervalo_anos': 'Total_anos_intervalo',\n",
    "    'Anos_completos_medidos': 'Numero_anos_completos',\n",
    "    'Anos_de_Falha': 'Numero_anos_falha',\n",
    "    'Porcentagem_anos_Falhas': 'Percentual_anos_falha',\n",
    "    'Media_Anual': 'Precipitacao_media_anual',\n",
    "}, inplace=True)\n",
    "\n",
    "# Arredondar as colunas selecionadas para 2 casas decimais\n",
    "colunas_para_arredondar = [col for col in database.columns if col not in ['Coordenada_X', 'Coordenada_Y']]\n",
    "database[colunas_para_arredondar] = database[colunas_para_arredondar].round(2)\n",
    "database['Coordenada_X'] = database['Coordenada_X'].round(8)\n",
    "database['Coordenada_Y'] = database['Coordenada_Y'].round(8)\n",
    "\n",
    "# Geração do DATAFRAME que será inserido no banco de dados\n",
    "database.to_csv('../data/maindatabase.csv', index=False, decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4aa576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração do dataframe usado na tabela no site.\n"
     ]
    }
   ],
   "source": [
    "print (\"Geração do dataframe usado na tabela no site.\") \n",
    "\n",
    "#print(Anos_completos.columns)\n",
    "\n",
    "colunas_resumo = [\n",
    "    'id','link_csv', 'Postos', 'Municipios', 'Latitude', 'Longitude', 'Ano_inicial', 'Ano_final',\n",
    "    'Primeiro_mes', 'Ultimo_mes', 'Intervalo_dias', 'dias_medidos', 'Total_Falhas',\n",
    "    'Porcentagem_dias_Falhas', 'Total_meses_intervalo', 'Numero_meses_completos',\n",
    "    'Meses_de_Falha', 'Percentual_meses_falha', 'Intervalo_anos', 'Anos_completos_medidos',\n",
    "    'Anos_de_Falha', 'Porcentagem_anos_Falhas', 'Media_Anual', 'Media_Jan', 'Media_Fev',\n",
    "    'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug',\n",
    "    'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec'\n",
    "]\n",
    "\n",
    "links_df = pd.read_csv('../data/links.csv', header=None, names=['id', 'link_csv'], encoding='latin1')\n",
    "\n",
    "Anos_completos['id'] = Anos_completos['id'].astype(str)\n",
    "\n",
    "links_df['id'] = links_df['id'].astype(str)\n",
    "\n",
    "Anos_completos = Anos_completos.merge(links_df, on='id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff095116",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Postos', 'Municipios', 'Latitude', 'Longitude', 'Ano_inicial', 'Ano_final', 'Primeiro_mes', 'Ultimo_mes', 'Intervalo_dias', 'dias_medidos', 'Total_Falhas', 'Porcentagem_dias_Falhas', 'Meses_de_Falha', 'Intervalo_anos', 'Anos_completos_medidos', 'Anos_de_Falha', 'Porcentagem_anos_Falhas', 'Media_Anual'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 22\u001b[0m\n\u001b[0;32m     11\u001b[0m colunas_resumo \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink_csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMunicipios\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAno_inicial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAno_final\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrimeiro_mes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUltimo_mes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntervalo_dias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdias_medidos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Falhas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Sep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Oct\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Nov\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Dec\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Criar o DataFrame df_resumo a partir de Anos_completos\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df_resumo \u001b[38;5;241m=\u001b[39m \u001b[43mAnos_completos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_resumo\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Agrupar por 'id' e selecionar a primeira ocorrência de cada grupo\u001b[39;00m\n\u001b[0;32m     25\u001b[0m df_resumo \u001b[38;5;241m=\u001b[39m df_resumo\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Postos', 'Municipios', 'Latitude', 'Longitude', 'Ano_inicial', 'Ano_final', 'Primeiro_mes', 'Ultimo_mes', 'Intervalo_dias', 'dias_medidos', 'Total_Falhas', 'Porcentagem_dias_Falhas', 'Meses_de_Falha', 'Intervalo_anos', 'Anos_completos_medidos', 'Anos_de_Falha', 'Porcentagem_anos_Falhas', 'Media_Anual'] not in index\""
     ]
    }
   ],
   "source": [
    "df_resumo = Anos_completos[colunas_resumo].copy()\n",
    "\n",
    "df_resumo = df_resumo.groupby('id').first().reset_index()\n",
    "\n",
    "# Renomear as colunas conforme o formato desejado\n",
    "df_resumo.rename(columns={\n",
    "    'id': 'ID',\n",
    "    'Postos': 'Nome_Posto',\n",
    "    'Municipios': 'Nome_Municipio',\n",
    "    'Latitude': 'Coordenada_Y',\n",
    "    'Longitude': 'Coordenada_X',\n",
    "    'Ano_inicial': 'Ano_Inicio',\n",
    "    'Ano_final': 'Ano_Fim',\n",
    "    'Primeiro_mes': 'Mes_Inicio',\n",
    "    'Ultimo_mes': 'Mes_Fim',\n",
    "    'Intervalo_dias': 'Total_dias_intervalo',\n",
    "    'dias_medidos': 'Dias_dados_medidos',\n",
    "    'Total_Falhas': 'Dias_falhos',\n",
    "    'Porcentagem_dias_Falhas': 'Percentual_dias_falhos',\n",
    "    'Total_meses_intervalo': 'Total_meses_intervalo',\n",
    "    'Numero_meses_completos': 'Numero_meses_completos',\n",
    "    'Meses_de_Falha': 'Numero_meses_falha',\n",
    "    'Percentual_meses_falha': 'Percentual_meses_falha',\n",
    "    'Intervalo_anos': 'Total_anos_intervalo',\n",
    "    'Anos_completos_medidos': 'Numero_anos_completos',\n",
    "    'Anos_de_Falha': 'Numero_anos_falha',\n",
    "    'Porcentagem_anos_Falhas': 'Percentual_anos_falha',\n",
    "    'Media_Anual': 'Precipitacao_media_anual',\n",
    "    'Media_Jan': 'Mes_Jan',\n",
    "    'Media_Fev': 'Mes_Fev',\n",
    "    'Media_Mar': 'Mes_Mar',\n",
    "    'Media_Apr': 'Mes_Apr',\n",
    "    'Media_May': 'Mes_May',\n",
    "    'Media_Jun': 'Mes_Jun',\n",
    "    'Media_Jul': 'Mes_Jul',\n",
    "    'Media_Aug': 'Mes_Aug',\n",
    "    'Media_Sep': 'Mes_Sep',\n",
    "    'Media_Oct': 'Mes_Oct',\n",
    "    'Media_Nov': 'Mes_Nov',\n",
    "    'Media_Dec': 'Mes_Dec'\n",
    "}, inplace=True)\n",
    "\n",
    "# Converter a coluna 'ID' para numérica para evitar problemas de ordenação\n",
    "df_resumo['ID'] = pd.to_numeric(df_resumo['ID'], errors='coerce')\n",
    "\n",
    "# Remover linhas com valores NaN na coluna 'ID' (se houver)\n",
    "df_resumo.dropna(subset=['ID'], inplace=True)\n",
    "\n",
    "# Ordenar com base na coluna 'ID'\n",
    "df_resumo.sort_values(by='ID', inplace=True)\n",
    "\n",
    "# Arredondar todas as médias e percentuais para 2 casas decimais\n",
    "colunas_arredondar = [\n",
    "    'Precipitacao_media_anual', 'Mes_Jan', 'Mes_Fev', 'Mes_Mar', 'Mes_Apr', 'Mes_May',\n",
    "    'Mes_Jun', 'Mes_Jul', 'Mes_Aug', 'Mes_Sep', 'Mes_Oct', 'Mes_Nov', 'Mes_Dec',\n",
    "    'Percentual_dias_falhos', 'Percentual_meses_falha', 'Percentual_anos_falha'\n",
    "]\n",
    "df_resumo[colunas_arredondar] = df_resumo[colunas_arredondar].round(2)\n",
    "\n",
    "# Salvar o DataFrame em um arquivo CSV\n",
    "df_resumo.to_csv('../data/resumo_postos_individual.csv', index=False, decimal=',')\n",
    "\n",
    "# Diagnóstico para verificar duplicados ou valores nulos na coluna 'ID'\n",
    "duplicados = df_resumo['ID'].duplicated().sum()\n",
    "valores_nulos = df_resumo['ID'].isnull().sum()\n",
    "\n",
    "print(f\"Duplicados em 'ID': {duplicados}\")\n",
    "print(f\"Valores nulos em 'ID': {valores_nulos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d4ac227",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'link_csv'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(links_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f93ae2c",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Nome_Municipio', 'Nome_Posto', 'Coordenada_Y', 'Coordenada_X',\n",
      "       'Anos', 'Meses', 'Total', 'Dia1', 'Dia2', 'Dia3', 'Dia4', 'Dia5',\n",
      "       'Dia6', 'Dia7', 'Dia8', 'Dia9', 'Dia10', 'Dia11', 'Dia12', 'Dia13',\n",
      "       'Dia14', 'Dia15', 'Dia16', 'Dia17', 'Dia18', 'Dia19', 'Dia20', 'Dia21',\n",
      "       'Dia22', 'Dia23', 'Dia24', 'Dia25', 'Dia26', 'Dia27', 'Dia28', 'Dia29',\n",
      "       'Dia30', 'Dia31', 'Ano_Inicio', 'Ano_Fim', 'Mes_Inicio', 'Mes_Fim',\n",
      "       'Numero_meses_falha', 'Total_dias_intervalo', 'Dias_falhos',\n",
      "       'Total_anos_intervalo', 'Dias_dados_medidos', 'Percentual_dias_falhos',\n",
      "       'Numero_anos_falha', 'Numero_anos_completos', 'Percentual_anos_falha',\n",
      "       'Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May',\n",
      "       'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct',\n",
      "       'Media_Nov', 'Media_Dec', 'Precipitacao_media_anual',\n",
      "       'Total_meses_intervalo', 'Numero_meses_completos',\n",
      "       'Percentual_meses_falha', 'link_csv_x', 'link_csv_y', 'link_csv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Anos_completos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a41a48",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Nome_Municipio', 'Nome_Posto', 'Coordenada_Y', 'Coordenada_X',\n",
      "       'Anos', 'Meses', 'Total', 'Dia1', 'Dia2', 'Dia3', 'Dia4', 'Dia5',\n",
      "       'Dia6', 'Dia7', 'Dia8', 'Dia9', 'Dia10', 'Dia11', 'Dia12', 'Dia13',\n",
      "       'Dia14', 'Dia15', 'Dia16', 'Dia17', 'Dia18', 'Dia19', 'Dia20', 'Dia21',\n",
      "       'Dia22', 'Dia23', 'Dia24', 'Dia25', 'Dia26', 'Dia27', 'Dia28', 'Dia29',\n",
      "       'Dia30', 'Dia31', 'Ano_Inicio', 'Ano_Fim', 'Mes_Inicio', 'Mes_Fim',\n",
      "       'Numero_meses_falha', 'Total_dias_intervalo', 'Dias_falhos',\n",
      "       'Total_anos_intervalo', 'Dias_dados_medidos', 'Percentual_dias_falhos',\n",
      "       'Numero_anos_falha', 'Numero_anos_completos', 'Percentual_anos_falha',\n",
      "       'Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May',\n",
      "       'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct',\n",
      "       'Media_Nov', 'Media_Dec', 'Precipitacao_media_anual',\n",
      "       'Total_meses_intervalo', 'Numero_meses_completos',\n",
      "       'Percentual_meses_falha', 'link_csv_x', 'link_csv_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "Anos_completos.rename(columns={'ID': 'id'}, inplace=True)\n",
    "print(Anos_completos.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fde6e-3862-46e4-a87e-71ea35f29335",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "# Converter todos os valores numéricos para strings\n",
    "df_resumo = df_resumo.map(\n",
    "    lambda x: str(x) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', texto)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "df_resumo = df_resumo.map(lambda x: remover_acentos(x)\n",
    "                                              if isinstance(x, str) else x)\n",
    "\n",
    "# Converter o dataframe para uma lista de dicionários\n",
    "dados_formatados_resumo = df_resumo.to_dict(orient='records')\n",
    "\n",
    "# Ler o arquivo links.csv com encoding 'latin1'\n",
    "links_df = pd.read_csv('../data/links.csv', header=None, names=['link_csv'], encoding='latin1')\n",
    "\n",
    "# Verificar se a coluna 'link_csv' existe\n",
    "if 'link_csv' not in links_df.columns:\n",
    "    raise ValueError(\"A coluna 'link_csv' não foi encontrada no arquivo links.csv\")\n",
    "\n",
    "# Verificar se o comprimento de links_df e df_resumo são iguais\n",
    "if len(links_df) != len(df_resumo):\n",
    "    raise ValueError(f\"O comprimento de links_df ({len(links_df)}) não corresponde ao comprimento de df_resumo ({len(df_resumo)})\")\n",
    "\n",
    "# Adicionar a coluna link_csv ao dataframe df_resumo\n",
    "df_resumo['link_csv'] = links_df['link_csv'].values\n",
    "\n",
    "colunas = list(df_resumo.columns)  # Obtém a lista de colunas\n",
    "colunas.insert(1, colunas.pop(colunas.index('link_csv')))  # Move 'link_csv' para a segunda posição\n",
    "df_resumo = df_resumo[colunas]  # Reorganiza o DataFrame com a nova ordem de colunas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db84d90",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/dados_formatados_resumo.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dados_formatados_resumo, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Arquivo JSON gerado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

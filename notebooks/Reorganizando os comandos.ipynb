{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bcfcdc-a349-487b-9edf-f830bfde23fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lendo dados das estações pluviometricas...\n"
     ]
    }
   ],
   "source": [
    "import zipfile as zipfile\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "print(\"\\nLendo dados das estações pluviometricas...\")\n",
    "\n",
    "for_concat = []\n",
    "with zipfile.ZipFile('../data/postos.zip', 'r') as t:\n",
    "    for arq in t.namelist():\n",
    "        if arq.endswith('.txt'):\n",
    "            with t.open(arq) as f:\n",
    "                df = pd.read_csv(f, delimiter=';')\n",
    "                # Extrair o ID do nome do arquivo e adicionar como uma nova coluna\n",
    "                df['id'] = arq.split('.')[0]\n",
    "                for_concat.append(df)\n",
    "\n",
    "# Exclude empty or all-NA entries before concatenation\n",
    "for_concat = [\n",
    "    df for df in for_concat if not df.empty and not df.isna().all().all()\n",
    "]\n",
    "\n",
    "registros_chuvas = pd.concat(for_concat)\n",
    "registros_chuvas.fillna(0, inplace=True)\n",
    "registros_chuvas.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reordenar as colunas para que 'id' seja a primeira\n",
    "cols = ['id'] + [col for col in registros_chuvas.columns if col != 'id']\n",
    "registros_chuvas = registros_chuvas[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d8892f-9aed-45f8-a807-fc5116dbc06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtrando anos completos...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltrando anos completos...\")\n",
    "\n",
    "#pegar apenas os anos completos\n",
    "registros_chuvas['Anos'] = registros_chuvas['Anos'].astype(int)\n",
    "registros_chuvas['Meses'] = registros_chuvas['Meses'].astype(int)\n",
    "ano = dt.datetime.now().year\n",
    "Anos_completos = registros_chuvas\n",
    "Anos_completos = Anos_completos.loc[Anos_completos['Anos'] < ano]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbfa536-53b4-4d1e-8424-55aca3716ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando o primeiro e o ultimo ano de registro de cada posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando o primeiro e o ultimo ano de registro de cada posto...\")\n",
    "\n",
    "# Verificar qual o primeiro ano de registro e o ultimo ano de registro de cada posto\n",
    "primeiro_e_ultimo_ano = Anos_completos.groupby('id')['Anos'].agg(['min', 'max'])\n",
    "primeiro_e_ultimo_ano.columns = ['Ano_inicial', 'Ano_final']\n",
    "Anos_completos = Anos_completos.merge(primeiro_e_ultimo_ano, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe1aeee-ae6e-4150-8abb-52eaffc709ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar qual foi o primeiro mês registrado para cada posto no ano inicial\n",
    "ano_inicial_df = Anos_completos[Anos_completos['Anos'] == Anos_completos['Ano_inicial']]\n",
    "primeiro_mes_ano_inicial = ano_inicial_df.groupby('id')['Meses'].min().reset_index()\n",
    "primeiro_mes_ano_inicial.rename(columns={'Meses': 'Primeiro_mes'}, inplace=True)\n",
    "Anos_completos = Anos_completos.merge(primeiro_mes_ano_inicial, on='id', how='left')\n",
    "\n",
    "# Encontrar qual foi o último mês registrado para cada posto no ano final\n",
    "ano_final_df = Anos_completos[Anos_completos['Anos'] == Anos_completos['Ano_final']]\n",
    "ultimo_mes_ano_final = ano_final_df.groupby('id')['Meses'].max().reset_index()\n",
    "ultimo_mes_ano_final.rename(columns={'Meses': 'Ultimo_mes'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15b32e2-2c55-4acb-95d4-22a4372b9083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def preencher_anos_faltantes(df):\n",
    "    postos_unicos = df[['id', 'Postos', 'Municipios']].drop_duplicates()\n",
    "    anos_faltantes = []\n",
    "    ano_atual = datetime.now().year  # Obtém o ano atual\n",
    "\n",
    "    for _, row in postos_unicos.iterrows():\n",
    "        posto_id = row['id']\n",
    "        posto = row['Postos']\n",
    "        municipio = row['Municipios']\n",
    "\n",
    "        # Seleciona apenas os registros do posto específico\n",
    "        df_posto = df[(df['id'] == posto_id) & (df['Postos'] == posto) & (df['Municipios'] == municipio)]\n",
    "        \n",
    "        # Identifica o primeiro ano registrado, preenchendo se for NaN\n",
    "        if df_posto['Anos'].notna().any():\n",
    "            ano_inicial = int(df_posto['Anos'].min())\n",
    "        else:\n",
    "            print(f\"Aviso: Nenhum ano encontrado para o posto ID {posto_id} - {posto}, município {municipio}. Preenchendo com 999.\")\n",
    "            ano_inicial = ano_atual  # Usar o ano atual como referência mínima\n",
    "        \n",
    "        # Determina o intervalo de anos\n",
    "        anos_completos = set(range(ano_inicial, ano_atual))\n",
    "        anos_registrados = set(df_posto['Anos'].dropna().unique())\n",
    "        \n",
    "        # Determina os anos que estão faltando\n",
    "        anos_faltantes_posto = anos_completos - anos_registrados\n",
    "\n",
    "        # Preenche os anos faltantes com os meses e dias como 999.0\n",
    "        for ano in anos_faltantes_posto:\n",
    "            for mes in range(1, 13):\n",
    "                falha = {\n",
    "                    'id': posto_id,\n",
    "                    'Municipios': municipio,\n",
    "                    'Postos': posto,\n",
    "                    'Latitude': df_posto['Latitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Longitude': df_posto['Longitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Anos': ano,\n",
    "                    'Meses': mes,\n",
    "                    'Total': 999.0,\n",
    "                    **{f'Dia{i}': 999.0 for i in range(1, 32)}\n",
    "                }\n",
    "                anos_faltantes.append(falha)\n",
    "\n",
    "    # Cria um DataFrame com os anos faltantes e concatena ao original\n",
    "    df_faltantes = pd.DataFrame(anos_faltantes)\n",
    "    df = pd.concat([df, df_faltantes], ignore_index=True)\n",
    "    df.sort_values(by=['id', 'Postos', 'Municipios', 'Anos', 'Meses'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preencher_meses_faltantes(df):\n",
    "    postos_unicos = df[['id', 'Postos', 'Municipios']].drop_duplicates()\n",
    "    meses_faltantes = []\n",
    "\n",
    "    for _, row in postos_unicos.iterrows():\n",
    "        posto_id = row['id']\n",
    "        posto = row['Postos']\n",
    "        municipio = row['Municipios']\n",
    "\n",
    "        # Seleciona apenas os registros do posto específico\n",
    "        df_posto = df[(df['id'] == posto_id) & (df['Postos'] == posto) & (df['Municipios'] == municipio)]\n",
    "        \n",
    "        anos_registrados = df_posto['Anos'].dropna().unique()\n",
    "\n",
    "        for ano in anos_registrados:\n",
    "            df_ano = df_posto[df_posto['Anos'] == ano]\n",
    "            meses_registrados = set(df_ano['Meses'].dropna().unique())\n",
    "            meses_completos = set(range(1, 13))\n",
    "            \n",
    "            # Determina os meses que estão faltando no ano\n",
    "            meses_faltantes_ano = meses_completos - meses_registrados\n",
    "\n",
    "            for mes in meses_faltantes_ano:\n",
    "                falha = {\n",
    "                    'id': posto_id,\n",
    "                    'Municipios': municipio,\n",
    "                    'Postos': posto,\n",
    "                    'Latitude': df_posto['Latitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Longitude': df_posto['Longitude'].iloc[0] if not df_posto.empty else 999.0,\n",
    "                    'Anos': ano,\n",
    "                    'Meses': mes,\n",
    "                    'Total': 999.0,\n",
    "                    **{f'Dia{i}': 999.0 for i in range(1, 32)}\n",
    "                }\n",
    "                meses_faltantes.append(falha)\n",
    "\n",
    "    # Cria um DataFrame com os meses faltantes e concatena ao original\n",
    "    df_faltantes = pd.DataFrame(meses_faltantes)\n",
    "    df = pd.concat([df, df_faltantes], ignore_index=True)\n",
    "    df.sort_values(by=['id', 'Postos', 'Municipios', 'Anos', 'Meses'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Preencher anos e meses faltantes\n",
    "Anos_completos = preencher_anos_faltantes(Anos_completos)\n",
    "Anos_completos = preencher_meses_faltantes(Anos_completos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4295ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivos CSV gerados para cada posto na pasta 'postos_solo'.\n"
     ]
    }
   ],
   "source": [
    "# Converter colunas numéricas de string para float\n",
    "numeric_cols = ['Total'] + [f'Dia{i}' for i in range(1, 32)]\n",
    "for col in numeric_cols:\n",
    "    Anos_completos[col] = Anos_completos[col].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"../data/postos_solo\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "for posto_id in Anos_completos['id'].unique():\n",
    "    registros_posto = Anos_completos[Anos_completos['id'] == posto_id]\n",
    "    nome_posto = registros_posto['Postos'].iloc[0].replace(' ', '_')\n",
    "    nome_posto = remover_acentos(nome_posto)  # Remover acentos\n",
    "    nome_arquivo = os.path.join(output_dir, f\"{posto_id}_{nome_posto}.csv\")\n",
    "    registros_posto.to_csv(nome_arquivo, index=False, decimal=',')\n",
    "\n",
    "print(\"\\nArquivos CSV gerados para cada posto na pasta 'postos_solo'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8524c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id Municipios         Postos  Latitude  Longitude  Anos  Meses  \\\n",
      "126348  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  1983      1   \n",
      "126349  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  1983      2   \n",
      "126350  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  1983      3   \n",
      "126351  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  1983      4   \n",
      "126352  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  1983      5   \n",
      "...     ...        ...            ...       ...        ...   ...    ...   \n",
      "126847  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  2024      8   \n",
      "126848  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  2024      9   \n",
      "126849  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  2024     10   \n",
      "126850  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  2024     11   \n",
      "126851  369   Redenção  ANTONIO DIOGO -4.316667     -38.75  2024     12   \n",
      "\n",
      "        Total   Dia1   Dia2  ...  Dia25  Dia26  Dia27  Dia28  Dia29  Dia30  \\\n",
      "126348   15.6    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   15.6   \n",
      "126349  144.6    0.0    0.0  ...    0.0    0.0    0.0    0.0  888.0  888.0   \n",
      "126350  178.0    0.0    0.0  ...   42.8    0.0   40.6   19.8    0.0    5.2   \n",
      "126351  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "126352   81.6    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   19.4   \n",
      "...       ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
      "126847  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "126848  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "126849  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "126850  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "126851  999.0  999.0  999.0  ...  999.0  999.0  999.0  999.0  999.0  999.0   \n",
      "\n",
      "        Dia31  Ano_inicial  Ano_final  Primeiro_mes  \n",
      "126348    0.0       1983.0     2008.0           1.0  \n",
      "126349  888.0       1983.0     2008.0           1.0  \n",
      "126350    0.0       1983.0     2008.0           1.0  \n",
      "126351  999.0          NaN        NaN           NaN  \n",
      "126352    0.0       1983.0     2008.0           1.0  \n",
      "...       ...          ...        ...           ...  \n",
      "126847  999.0          NaN        NaN           NaN  \n",
      "126848  999.0          NaN        NaN           NaN  \n",
      "126849  999.0          NaN        NaN           NaN  \n",
      "126850  999.0          NaN        NaN           NaN  \n",
      "126851  999.0          NaN        NaN           NaN  \n",
      "\n",
      "[504 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrar as linhas onde o id é 369\n",
    "linhas_id_369 = Anos_completos[Anos_completos['id'] == '369']\n",
    "print(linhas_id_369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01bcc81d-bb22-4da7-8a19-5378f533d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Repreenchendo os novos registros com os meses e anos de primeiro registro\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRepreenchendo os novos registros com os meses e anos de primeiro registro\")\n",
    "\n",
    "primeiro_e_ultimo_ano = Anos_completos.groupby('id')['Anos'].agg(['min', 'max'])\n",
    "primeiro_e_ultimo_ano.columns = ['Ano_inicial', 'Ano_final']\n",
    "Anos_completos = Anos_completos.merge(primeiro_e_ultimo_ano, on='id')\n",
    "\n",
    "# Check if the columns exist before attempting to drop them\n",
    "if 'Ano_inicial_x' in Anos_completos.columns and 'Ano_final_x' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Ano_inicial_x', 'Ano_final_x'], inplace=True)\n",
    "\n",
    "Anos_completos = Anos_completos.merge(primeiro_mes_ano_inicial, on='id', how='left')\n",
    "Anos_completos = Anos_completos.merge(ultimo_mes_ano_final, on='id', how='left')\n",
    "\n",
    "# Check if the column exists before attempting to drop it\n",
    "if 'Primeiro_mes_x' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Primeiro_mes_x'], inplace=True)\n",
    "\n",
    "Anos_completos.rename(columns={\n",
    "    'Ano_inicial_y': 'Ano_inicial',\n",
    "    'Ano_final_y': 'Ano_final',\n",
    "    'Primeiro_mes_y': 'Primeiro_mes'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff779014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando quantos meses de falha existem parada cada posto\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando quantos meses de falha existem parada cada posto\")\n",
    "\n",
    "df_sem_extras = Anos_completos.drop(\n",
    "    columns=['Primeiro_mes', 'Ultimo_mes', 'Ano_inicial', 'Ano_final'])\n",
    "\n",
    "# Substituir os valores 888.0 por NaN e depois remover essas colunas\n",
    "df_sem_extras.replace(888.0, pd.NA, inplace=True)\n",
    "df_sem_extras.dropna(axis=1, how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8708f895-4d28-4256-9c66-4b142dd22e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando quantos meses de falha existem para cada posto\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando quantos meses de falha existem para cada posto\")\n",
    "dias_cols = [f'Dia{i}' for i in range(1, 32)]\n",
    "\n",
    "def verificar_meses_falha(df):\n",
    "    df['Mes_falha'] = df[dias_cols].apply(lambda row: any(day == 999.0 for day in row), axis=1)\n",
    "    meses_falha_por_posto = df.groupby('id')['Mes_falha'].sum()\n",
    "    return meses_falha_por_posto\n",
    "\n",
    "meses_falha_por_posto = verificar_meses_falha(Anos_completos)\n",
    "Anos_completos = Anos_completos.merge(meses_falha_por_posto.rename('Meses_de_Falha'), on='id', how='left')\n",
    "Anos_completos = Anos_completos.drop(columns=['Mes_falha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4788df56-ca3b-4395-abb1-d5d070337a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando intervalo de dias, meses e anos totais de falhas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\\nCalculando intervalo de dias, meses e anos totais de falhas por posto...\"\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def calcular_intervalo_dias(row):\n",
    "    ano_inicial = int(row['Ano_inicial'])\n",
    "    ano_final = int(row['Ano_final'])\n",
    "    data_inicial = datetime(ano_inicial, 1, 1)\n",
    "    data_final = datetime(ano_final, 12, 31)\n",
    "\n",
    "    intervalo = (data_final - data_inicial).days + 1\n",
    "    \n",
    "    for year in range(ano_inicial, ano_final + 1):\n",
    "        if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "            if year == ano_inicial and data_inicial.month > 2:\n",
    "                continue\n",
    "            if year == ano_final and data_final.month < 2:\n",
    "                continue\n",
    "            intervalo += 1\n",
    "\n",
    "    return intervalo\n",
    "\n",
    "def contar_dias_falha(row):\n",
    "    return sum(row[dia] == 999.0 for dia in dias_cols)\n",
    "\n",
    "Anos_completos['Ano_inicial'] = Anos_completos['Ano_inicial'].astype(int)\n",
    "Anos_completos['Ano_final'] = Anos_completos['Ano_final'].astype(int)\n",
    "\n",
    "Anos_completos['Intervalo_dias'] = Anos_completos.apply(calcular_intervalo_dias, axis=1)\n",
    "Anos_completos['Dias_de_Falha'] = Anos_completos.apply(contar_dias_falha, axis=1)\n",
    "\n",
    "total_falhas_por_posto = Anos_completos.groupby('id')['Dias_de_Falha'].sum().reset_index()\n",
    "total_falhas_por_posto.rename(columns={'Dias_de_Falha': 'Total_Falhas'}, inplace=True)\n",
    "\n",
    "Anos_completos = Anos_completos.merge(total_falhas_por_posto, on='id', how='left')\n",
    "Anos_completos['Intervalo_anos'] = (Anos_completos['Ano_final'].astype(int) - Anos_completos['Ano_inicial'].astype(int)) + 1\n",
    "Anos_completos['Intervalo_meses'] = Anos_completos['Intervalo_anos'] * 12\n",
    "\n",
    "Anos_completos.drop(columns=['Dias_de_Falha'], inplace=True)\n",
    "Anos_completos['dias_medidos'] = Anos_completos['Intervalo_dias'] - Anos_completos['Total_Falhas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7adeea-d814-4ba8-bb46-df3473c364c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a porcentagem de dias de falhas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a porcentagem de dias de falhas por posto...\")\n",
    "\n",
    "Anos_completos['Porcentagem_dias_Falhas'] = (\n",
    "    Anos_completos['Total_Falhas'] / Anos_completos['Intervalo_dias']) * 100\n",
    "Anos_completos['Porcentagem_dias_Falhas'] = Anos_completos[\n",
    "    'Porcentagem_dias_Falhas'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a854f833-4ddf-42f1-80bb-10e533202f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando anos de falha por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificando anos de falha por posto...\")\n",
    "\n",
    "# Verificar quantos anos com falha tiveram no intervalo por posto\n",
    "def contar_anos_falha(df):\n",
    "    df['Ano_com_falha'] = df[dias_cols].apply(lambda row: any(day == 999.0 for day in row), axis=1)\n",
    "    anos_falha = df.groupby(['id', 'Anos'])['Ano_com_falha'].any().reset_index()\n",
    "    anos_falha_por_posto = anos_falha.groupby('id')['Ano_com_falha'].sum().reset_index()\n",
    "    anos_falha_por_posto.rename(columns={'Ano_com_falha': 'Anos_de_Falha'}, inplace=True)\n",
    "    return anos_falha_por_posto\n",
    "\n",
    "anos_falha_por_posto = contar_anos_falha(Anos_completos)\n",
    "Anos_completos = Anos_completos.merge(anos_falha_por_posto, on='id', how='left')\n",
    "Anos_completos.drop(columns=['Ano_com_falha'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec99a7f2-4669-45eb-993f-44f5ca1c6504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando anos completos medidos por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando anos completos medidos por posto...\")\n",
    "\n",
    "# Agrupar por id para garantir que os dados são do mesmo posto\n",
    "Anos_completos['Anos_completos_medidos'] = Anos_completos.groupby('id')['Intervalo_anos'].transform('first') - Anos_completos.groupby('id')['Anos_de_Falha'].transform('first')\n",
    "\n",
    "Anos_completos['Porcentagem_anos_Falhas'] = (\n",
    "    Anos_completos['Anos_de_Falha'] / Anos_completos['Intervalo_anos']) * 100\n",
    "Anos_completos['Porcentagem_anos_Falhas'] = Anos_completos[\n",
    "    'Porcentagem_anos_Falhas'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40111eb-d6a6-45b9-8a26-3b88c5d1a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a média mensal de chuvas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a média mensal de chuvas por posto...\")\n",
    "\n",
    "def dados_validos(df):\n",
    "    # Verificar se todos os dias do mês não são 999.0\n",
    "    df['Mes_valido'] = df[dias_cols].apply(lambda row: all(day != 999.0 for day in row), axis=1)\n",
    "    \n",
    "    # Filtrar apenas os meses válidos\n",
    "    df_validos = df[df['Mes_valido']].copy()\n",
    "    \n",
    "    # Remover a coluna auxiliar 'Mes_valido'\n",
    "    df_validos.drop(columns=['Mes_valido'], inplace=True)\n",
    "    \n",
    "    return df_validos\n",
    "\n",
    "df_dados_validos = dados_validos(Anos_completos)\n",
    "\n",
    "# Calcular a média mensal de chuvas por posto\n",
    "ids_unicos = df_dados_validos['id'].unique()\n",
    "\n",
    "medias_mensais = []\n",
    "\n",
    "for posto_id in ids_unicos:\n",
    "    df_posto = df_dados_validos[df_dados_validos['id'] == posto_id]\n",
    "    \n",
    "    # Inicializar variáveis para somar os totais e contadores para cada mês\n",
    "    jan_total = fev_total = mar_total = apr_total = may_total = jun_total = 0\n",
    "    jul_total = aug_total = sep_total = oct_total = nov_total = dec_total = 0\n",
    "    \n",
    "    jan_count = fev_count = mar_count = apr_count = may_count = jun_count = 0\n",
    "    jul_count = aug_count = sep_count = oct_count = nov_count = dec_count = 0\n",
    "    \n",
    "    for _, row in df_posto.iterrows():\n",
    "        if row['Meses'] == 1:\n",
    "            jan_total += row['Total']\n",
    "            jan_count += 1\n",
    "        elif row['Meses'] == 2:\n",
    "            fev_total += row['Total']\n",
    "            fev_count += 1\n",
    "        elif row['Meses'] == 3:\n",
    "            mar_total += row['Total']\n",
    "            mar_count += 1\n",
    "        elif row['Meses'] == 4:\n",
    "            apr_total += row['Total']\n",
    "            apr_count += 1\n",
    "        elif row['Meses'] == 5:\n",
    "            may_total += row['Total']\n",
    "            may_count += 1\n",
    "        elif row['Meses'] == 6:\n",
    "            jun_total += row['Total']\n",
    "            jun_count += 1\n",
    "        elif row['Meses'] == 7:\n",
    "            jul_total += row['Total']\n",
    "            jul_count += 1\n",
    "        elif row['Meses'] == 8:\n",
    "            aug_total += row['Total']\n",
    "            aug_count += 1\n",
    "        elif row['Meses'] == 9:\n",
    "            sep_total += row['Total']\n",
    "            sep_count += 1\n",
    "        elif row['Meses'] == 10:\n",
    "            oct_total += row['Total']\n",
    "            oct_count += 1\n",
    "        elif row['Meses'] == 11:\n",
    "            nov_total += row['Total']\n",
    "            nov_count += 1\n",
    "        elif row['Meses'] == 12:\n",
    "            dec_total += row['Total']\n",
    "            dec_count += 1\n",
    "    \n",
    "    medias_mensais.append({\n",
    "        'id': posto_id,\n",
    "        'Media_Jan': jan_total / jan_count if jan_count else 999,\n",
    "        'Media_Fev': fev_total / fev_count if fev_count else 999,\n",
    "        'Media_Mar': mar_total / mar_count if mar_count else 999,\n",
    "        'Media_Apr': apr_total / apr_count if apr_count else 999,\n",
    "        'Media_May': may_total / may_count if may_count else 999,\n",
    "        'Media_Jun': jun_total / jun_count if jun_count else 999,\n",
    "        'Media_Jul': jul_total / jul_count if jul_count else 999,\n",
    "        'Media_Aug': aug_total / aug_count if aug_count else 999,\n",
    "        'Media_Sep': sep_total / sep_count if sep_count else 999,\n",
    "        'Media_Oct': oct_total / oct_count if oct_count else 999,\n",
    "        'Media_Nov': nov_total / nov_count if nov_count else 999,\n",
    "        'Media_Dec': dec_total / dec_count if dec_count else 999\n",
    "    })\n",
    "\n",
    "df_medias_mensais = pd.DataFrame(medias_mensais)\n",
    "Anos_completos = Anos_completos.merge(df_medias_mensais, on='id', how='left')\n",
    "# Preencher médias vazias com 999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8038910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_cols = ['Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec']\n",
    "Anos_completos[medias_cols] = Anos_completos[medias_cols].fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb20ace9-05b0-4ce6-b53c-e460548588ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando a média anual de chuvas por posto...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculando a média anual de chuvas por posto...\")\n",
    "\n",
    "postos_unicos = Anos_completos['id'].unique()\n",
    "\n",
    "Anos_completos['Media_Anual'] = 0.0\n",
    "\n",
    "for posto_id in postos_unicos:\n",
    "    df_posto = Anos_completos[Anos_completos['id'] == posto_id]\n",
    "    intervalo_anos = df_posto['Intervalo_anos'].iloc[0]\n",
    "\n",
    "    # Check if all monthly averages are 999\n",
    "    if (df_posto[['Media_Jan', 'Media_Fev', 'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug', 'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec']] == 999).all(axis=None):\n",
    "        media_anual = 999\n",
    "    else:\n",
    "        soma_total_chuvas = df_posto[df_posto['Total'] != 999].groupby('Anos')['Total'].sum().sum()\n",
    "        media_anual = soma_total_chuvas / intervalo_anos\n",
    "\n",
    "    Anos_completos.loc[Anos_completos['id'] == posto_id, 'Media_Anual'] = media_anual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91b88347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anos_completos['Total_meses_intervalo'] = Anos_completos['Intervalo_anos'] * 12\n",
    "\n",
    "if 'Intervalo_meses' in Anos_completos.columns:\n",
    "    Anos_completos.drop(columns=['Intervalo_meses'], inplace=True)\n",
    "\n",
    "Anos_completos['Numero_meses_completos'] = Anos_completos['Total_meses_intervalo'] - Anos_completos['Meses_de_Falha']\n",
    "\n",
    "def calcular_percentual_meses_falha(df):\n",
    "    df['Percentual_meses_falha'] = (df['Meses_de_Falha'] / df['Total_meses_intervalo']) * 100\n",
    "    df['Percentual_meses_falha'] = df['Percentual_meses_falha'].round(2)\n",
    "    return df\n",
    "\n",
    "Anos_completos = calcular_percentual_meses_falha(Anos_completos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff095116",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['link_csv'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m      4\u001b[0m colunas_resumo \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink_csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMunicipios\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAno_inicial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAno_final\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrimeiro_mes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUltimo_mes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntervalo_dias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdias_medidos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Falhas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Sep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Oct\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Nov\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia_Dec\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Criar o DataFrame df_resumo a partir de Anos_completos\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_resumo \u001b[38;5;241m=\u001b[39m \u001b[43mAnos_completos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_resumo\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Agrupar por 'id' e selecionar a primeira ocorrência de cada grupo\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df_resumo \u001b[38;5;241m=\u001b[39m df_resumo\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['link_csv'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "links_df = pd.read_csv('../data/links.csv', header=None, names=['link_csv'], encoding='latin1')\n",
    "\n",
    "Anos_completos['link_csv'] = links_df['link_csv'].values\n",
    "\n",
    "# Selecionar as colunas necessárias e renomeá-las conforme o formato desejado\n",
    "colunas_resumo = [\n",
    "    'id','link_csv', 'Postos', 'Municipios', 'Latitude', 'Longitude', 'Ano_inicial', 'Ano_final',\n",
    "    'Primeiro_mes', 'Ultimo_mes', 'Intervalo_dias', 'dias_medidos', 'Total_Falhas',\n",
    "    'Porcentagem_dias_Falhas', 'Total_meses_intervalo', 'Numero_meses_completos',\n",
    "    'Meses_de_Falha', 'Percentual_meses_falha', 'Intervalo_anos', 'Anos_completos_medidos',\n",
    "    'Anos_de_Falha', 'Porcentagem_anos_Falhas', 'Media_Anual', 'Media_Jan', 'Media_Fev',\n",
    "    'Media_Mar', 'Media_Apr', 'Media_May', 'Media_Jun', 'Media_Jul', 'Media_Aug',\n",
    "    'Media_Sep', 'Media_Oct', 'Media_Nov', 'Media_Dec'\n",
    "]\n",
    "\n",
    "# Criar o DataFrame df_resumo a partir de Anos_completos\n",
    "df_resumo = Anos_completos[colunas_resumo].copy()\n",
    "\n",
    "# Agrupar por 'id' e selecionar a primeira ocorrência de cada grupo\n",
    "df_resumo = df_resumo.groupby('id').first().reset_index()\n",
    "\n",
    "# Renomear as colunas conforme o formato desejado\n",
    "df_resumo.rename(columns={\n",
    "    'id': 'ID',\n",
    "    'Postos': 'Nome_Posto',\n",
    "    'Municipios': 'Nome_Municipio',\n",
    "    'Latitude': 'Coordenada_Y',\n",
    "    'Longitude': 'Coordenada_X',\n",
    "    'Ano_inicial': 'Ano_Inicio',\n",
    "    'Ano_final': 'Ano_Fim',\n",
    "    'Primeiro_mes': 'Mes_Inicio',\n",
    "    'Ultimo_mes': 'Mes_Fim',\n",
    "    'Intervalo_dias': 'Total_dias_intervalo',\n",
    "    'dias_medidos': 'Dias_dados_medidos',\n",
    "    'Total_Falhas': 'Dias_falhos',\n",
    "    'Porcentagem_dias_Falhas': 'Percentual_dias_falhos',\n",
    "    'Total_meses_intervalo': 'Total_meses_intervalo',\n",
    "    'Numero_meses_completos': 'Numero_meses_completos',\n",
    "    'Meses_de_Falha': 'Numero_meses_falha',\n",
    "    'Percentual_meses_falha': 'Percentual_meses_falha',\n",
    "    'Intervalo_anos': 'Total_anos_intervalo',\n",
    "    'Anos_completos_medidos': 'Numero_anos_completos',\n",
    "    'Anos_de_Falha': 'Numero_anos_falha',\n",
    "    'Porcentagem_anos_Falhas': 'Percentual_anos_falha',\n",
    "    'Media_Anual': 'Precipitacao_media_anual',\n",
    "    'Media_Jan': 'Mes_Jan',\n",
    "    'Media_Fev': 'Mes_Fev',\n",
    "    'Media_Mar': 'Mes_Mar',\n",
    "    'Media_Apr': 'Mes_Apr',\n",
    "    'Media_May': 'Mes_May',\n",
    "    'Media_Jun': 'Mes_Jun',\n",
    "    'Media_Jul': 'Mes_Jul',\n",
    "    'Media_Aug': 'Mes_Aug',\n",
    "    'Media_Sep': 'Mes_Sep',\n",
    "    'Media_Oct': 'Mes_Oct',\n",
    "    'Media_Nov': 'Mes_Nov',\n",
    "    'Media_Dec': 'Mes_Dec'\n",
    "}, inplace=True)\n",
    "\n",
    "# Converter a coluna 'ID' para numérica para evitar problemas de ordenação\n",
    "df_resumo['ID'] = pd.to_numeric(df_resumo['ID'], errors='coerce')\n",
    "\n",
    "# Remover linhas com valores NaN na coluna 'ID' (se houver)\n",
    "df_resumo.dropna(subset=['ID'], inplace=True)\n",
    "\n",
    "# Ordenar com base na coluna 'ID'\n",
    "df_resumo.sort_values(by='ID', inplace=True)\n",
    "\n",
    "# Arredondar todas as médias e percentuais para 2 casas decimais\n",
    "colunas_arredondar = [\n",
    "    'Precipitacao_media_anual', 'Mes_Jan', 'Mes_Fev', 'Mes_Mar', 'Mes_Apr', 'Mes_May',\n",
    "    'Mes_Jun', 'Mes_Jul', 'Mes_Aug', 'Mes_Sep', 'Mes_Oct', 'Mes_Nov', 'Mes_Dec',\n",
    "    'Percentual_dias_falhos', 'Percentual_meses_falha', 'Percentual_anos_falha'\n",
    "]\n",
    "df_resumo[colunas_arredondar] = df_resumo[colunas_arredondar].round(2)\n",
    "\n",
    "# Salvar o DataFrame em um arquivo CSV\n",
    "df_resumo.to_csv('../data/resumo_postos_individual.csv', index=False, decimal=',')\n",
    "\n",
    "# Diagnóstico para verificar duplicados ou valores nulos na coluna 'ID'\n",
    "duplicados = df_resumo['ID'].duplicated().sum()\n",
    "valores_nulos = df_resumo['ID'].isnull().sum()\n",
    "\n",
    "print(f\"Duplicados em 'ID': {duplicados}\")\n",
    "print(f\"Valores nulos em 'ID': {valores_nulos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fde6e-3862-46e4-a87e-71ea35f29335",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo JSON gerado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Converter todos os valores numéricos para strings\n",
    "df_resumo = df_resumo.map(\n",
    "    lambda x: str(x) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "def remover_acentos(texto):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', texto)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "df_resumo = df_resumo.map(lambda x: remover_acentos(x)\n",
    "                                              if isinstance(x, str) else x)\n",
    "\n",
    "# Converter o dataframe para uma lista de dicionários\n",
    "dados_formatados_resumo = df_resumo.to_dict(orient='records')\n",
    "\n",
    "# Ler o arquivo links.csv com encoding 'latin1'\n",
    "links_df = pd.read_csv('../data/links.csv', header=None, names=['link_csv'], encoding='latin1')\n",
    "\n",
    "# Verificar se a coluna 'link_csv' existe\n",
    "if 'link_csv' not in links_df.columns:\n",
    "    raise ValueError(\"A coluna 'link_csv' não foi encontrada no arquivo links.csv\")\n",
    "\n",
    "# Verificar se o comprimento de links_df e df_resumo são iguais\n",
    "if len(links_df) != len(df_resumo):\n",
    "    raise ValueError(f\"O comprimento de links_df ({len(links_df)}) não corresponde ao comprimento de df_resumo ({len(df_resumo)})\")\n",
    "\n",
    "# Adicionar a coluna link_csv ao dataframe df_resumo\n",
    "df_resumo['link_csv'] = links_df['link_csv'].values\n",
    "\n",
    "colunas = list(df_resumo.columns)  # Obtém a lista de colunas\n",
    "colunas.insert(1, colunas.pop(colunas.index('link_csv')))  # Move 'link_csv' para a segunda posição\n",
    "df_resumo = df_resumo[colunas]  # Reorganiza o DataFrame com a nova ordem de colunas\n",
    "\n",
    "# Salvar a lista de dicionários em um arquivo JSON\n",
    "with open('../data/dados_formatados_resumo.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dados_formatados_resumo, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Arquivo JSON gerado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f67e9e",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>link_csv</th>\n",
       "      <th>Nome_Posto</th>\n",
       "      <th>Nome_Municipio</th>\n",
       "      <th>Coordenada_Y</th>\n",
       "      <th>Coordenada_X</th>\n",
       "      <th>Ano_Inicio</th>\n",
       "      <th>Ano_Fim</th>\n",
       "      <th>Mes_Inicio</th>\n",
       "      <th>Mes_Fim</th>\n",
       "      <th>...</th>\n",
       "      <th>Mes_Mar</th>\n",
       "      <th>Mes_Apr</th>\n",
       "      <th>Mes_May</th>\n",
       "      <th>Mes_Jun</th>\n",
       "      <th>Mes_Jul</th>\n",
       "      <th>Mes_Aug</th>\n",
       "      <th>Mes_Sep</th>\n",
       "      <th>Mes_Oct</th>\n",
       "      <th>Mes_Nov</th>\n",
       "      <th>Mes_Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>Abaiara</td>\n",
       "      <td>-7.3615277777778</td>\n",
       "      <td>-39.0355</td>\n",
       "      <td>1981</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>251.54</td>\n",
       "      <td>165.95</td>\n",
       "      <td>52.81</td>\n",
       "      <td>14.25</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12.05</td>\n",
       "      <td>28.54</td>\n",
       "      <td>66.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>ACARAU</td>\n",
       "      <td>Acarau</td>\n",
       "      <td>-2.8858888888889</td>\n",
       "      <td>-40.118416666667</td>\n",
       "      <td>1974</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>316.38</td>\n",
       "      <td>298.46</td>\n",
       "      <td>154.31</td>\n",
       "      <td>58.18</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.96</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>ACOPIARA</td>\n",
       "      <td>Acopiara</td>\n",
       "      <td>-6.11075</td>\n",
       "      <td>-39.442722222222</td>\n",
       "      <td>1973</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>175.66</td>\n",
       "      <td>157.21</td>\n",
       "      <td>95.0</td>\n",
       "      <td>37.15</td>\n",
       "      <td>23.71</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.67</td>\n",
       "      <td>7.72</td>\n",
       "      <td>7.43</td>\n",
       "      <td>30.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>4</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>AIUABA</td>\n",
       "      <td>Aiuaba</td>\n",
       "      <td>-6.567</td>\n",
       "      <td>-40.116694444444</td>\n",
       "      <td>1978</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>138.35</td>\n",
       "      <td>108.64</td>\n",
       "      <td>43.2</td>\n",
       "      <td>12.42</td>\n",
       "      <td>7.26</td>\n",
       "      <td>2.21</td>\n",
       "      <td>3.26</td>\n",
       "      <td>7.07</td>\n",
       "      <td>14.49</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>5</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>ALCANTARAS</td>\n",
       "      <td>Alcantaras</td>\n",
       "      <td>-3.5853611111111</td>\n",
       "      <td>-40.544222222222</td>\n",
       "      <td>1981</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>207.37</td>\n",
       "      <td>198.69</td>\n",
       "      <td>71.3</td>\n",
       "      <td>24.47</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>893</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>VICOSA 02</td>\n",
       "      <td>Maranguape</td>\n",
       "      <td>-3.9236111111111</td>\n",
       "      <td>-38.730444444444</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>262.8</td>\n",
       "      <td>287.75</td>\n",
       "      <td>127.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>894</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>SOLEDADE</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>-6.9286388888889</td>\n",
       "      <td>-38.776222222222</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>214.1</td>\n",
       "      <td>503.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>895</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>SITIO SANTA ISABEL</td>\n",
       "      <td>Baturite</td>\n",
       "      <td>-4.3416666666667</td>\n",
       "      <td>-38.945</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>896</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>Cemoaba</td>\n",
       "      <td>Tururu</td>\n",
       "      <td>-3.4621944444444</td>\n",
       "      <td>-39.423305555556</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>312.8</td>\n",
       "      <td>271.2</td>\n",
       "      <td>183.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>897</td>\n",
       "      <td>https://cdn.jsdelivr.net/gh/infracosteira/pluv...</td>\n",
       "      <td>Fazenda pedra vermelha</td>\n",
       "      <td>Taua</td>\n",
       "      <td>-6.2887431</td>\n",
       "      <td>-40.3991012</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           link_csv  \\\n",
       "0      1  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "111    2  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "216    3  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "305    4  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "386    5  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "..   ...                                                ...   \n",
       "811  893  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "812  894  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "813  895  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "814  896  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "815  897  https://cdn.jsdelivr.net/gh/infracosteira/pluv...   \n",
       "\n",
       "                 Nome_Posto Nome_Municipio      Coordenada_Y  \\\n",
       "0                   ABAIARA        Abaiara  -7.3615277777778   \n",
       "111                  ACARAU         Acarau  -2.8858888888889   \n",
       "216                ACOPIARA       Acopiara          -6.11075   \n",
       "305                  AIUABA         Aiuaba            -6.567   \n",
       "386              ALCANTARAS     Alcantaras  -3.5853611111111   \n",
       "..                      ...            ...               ...   \n",
       "811               VICOSA 02     Maranguape  -3.9236111111111   \n",
       "812                SOLEDADE         Aurora  -6.9286388888889   \n",
       "813      SITIO SANTA ISABEL       Baturite  -4.3416666666667   \n",
       "814                 Cemoaba         Tururu  -3.4621944444444   \n",
       "815  Fazenda pedra vermelha           Taua        -6.2887431   \n",
       "\n",
       "         Coordenada_X Ano_Inicio Ano_Fim Mes_Inicio Mes_Fim  ... Mes_Mar  \\\n",
       "0            -39.0355       1981    2024          1      12  ...  251.54   \n",
       "111  -40.118416666667       1974    2024          1      12  ...  316.38   \n",
       "216  -39.442722222222       1973    2024          5      12  ...  175.66   \n",
       "305  -40.116694444444       1978    2024          1      12  ...  138.35   \n",
       "386  -40.544222222222       1981    2024          1      12  ...  207.37   \n",
       "..                ...        ...     ...        ...     ...  ...     ...   \n",
       "811  -38.730444444444       2023    2024          3      10  ...   262.8   \n",
       "812  -38.776222222222       2023    2024         11      12  ...   214.1   \n",
       "813           -38.945       2024    2024          1      12  ...   265.0   \n",
       "814  -39.423305555556       2023    2024          1      12  ...   312.8   \n",
       "815       -40.3991012       2024    2024          7      12  ...   999.0   \n",
       "\n",
       "    Mes_Apr Mes_May Mes_Jun Mes_Jul Mes_Aug Mes_Sep Mes_Oct Mes_Nov Mes_Dec  \n",
       "0    165.95   52.81   14.25     6.2     1.0    3.58   12.05   28.54   66.19  \n",
       "111  298.46  154.31   58.18    21.5    2.76    0.88    1.93    3.96    17.4  \n",
       "216  157.21    95.0   37.15   23.71    6.38    4.67    7.72    7.43   30.58  \n",
       "305  108.64    43.2   12.42    7.26    2.21    3.26    7.07   14.49   38.14  \n",
       "386  198.69    71.3   24.47    6.94    0.89     0.0     0.0    3.08   13.18  \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "811  287.75   127.0    45.3     0.0     5.8     0.0     0.0     0.0     0.0  \n",
       "812   503.2    50.0    10.0    34.7     0.0     4.5     0.0     0.0    36.9  \n",
       "813   457.0   166.0   177.0    11.0     0.0     0.0     0.0     3.0   999.0  \n",
       "814   271.2   183.0    70.0     0.0     0.0     0.0     0.0     0.0    23.4  \n",
       "815   999.0   999.0   999.0    25.0     0.0     0.0     0.0     0.0    38.4  \n",
       "\n",
       "[827 rows x 35 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resumo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
